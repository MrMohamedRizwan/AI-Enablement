{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560e3f70ee6f6dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T10:33:44.768070Z",
     "start_time": "2026-01-12T10:33:44.724839Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "loader = WebBaseLoader(web_paths = ('https://en.wikipedia.org/wiki/LangChain',),\n",
    "                       bs_kwargs= dict(parse_only=bs4.SoupStrainer(\n",
    "                           class_ =(\"mw-body-content\", \"mw-first-heading\")\n",
    "                       )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b20e64d2b71ba003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T10:33:46.200518Z",
     "start_time": "2026-01-12T10:33:46.138694Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "webcontent = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cfa5a1c9d60471f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T10:10:04.570191Z",
     "start_time": "2026-01-12T10:10:04.558600Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap= 200)\n",
    "\n",
    "doc = text_splitter.split_documents(webcontent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229b1c46f7e2671f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T10:15:31.967756Z",
     "start_time": "2026-01-12T10:15:27.962163Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gc/_6pc4cjj1_39_1622f88r3d00000gt/T/ipykernel_96344/3055314890.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660303dfd494baf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T10:16:10.672405Z",
     "start_time": "2026-01-12T10:16:10.366398Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "db1 = FAISS.from_documents(\n",
    "    documents=doc[:50],\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9ab5a5dd3bf0847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-12T10:24:05.706394Z",
     "start_time": "2026-01-12T10:24:05.600461Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "db2 = Chroma.from_documents(\n",
    "    documents=doc,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "db2.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d3e3e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever1 = db1.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f6a658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever2 = db2.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f975fce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'History[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\nIn the third quarter of 2023, the LangChain Expression Language (LCEL) was introduced, which provides a declarative way to define chains of actions.[5][6]\\nIn October 2023 LangChain introduced LangServe, a deployment tool to host LCEL code as a production-ready API.[7]\\n\\nLanguage model application development framework\\nLangChainDeveloperHarrison ChaseInitial releaseOctober 2022Stable release0.1.16[1]\\n   / 11 April 2024; 21 months ago\\xa0(11 April 2024)\\nRepositorygithub.com/langchain-ai/langchainWritten inPython and JavaScriptTypeSoftware framework for large language model application developmentLicenseMIT LicenseWebsiteLangChain.com\\n\\nFree and open-source software portal\\nLangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\n\\n^ Griffith, Erin; Metz, Cade (2023-03-14). \"\\'Let 1,000 Flowers Bloom\\': A.I. Funding Frenzy Escalates\". The New York Times. ISSN\\xa00362-4331. Archived from the original on 2023-04-18. Retrieved 2023-04-18.\\n\\n^ Mansurova, Mariya (2023-10-30). \"Topic Modelling in production: Leveraging LangChain to move from ad-hoc Jupyter Notebooks to production modular service\". towardsdatascience.com. Retrieved 2024-07-08.\\n\\n^ \"LangChain Expression Language\". langchain.dev. 2023-08-01. Retrieved 2024-07-08.\\n\\n^ \"Introducing LangServe, the best way to deploy your LangChains\". LangChain Blog. 2023-10-12. Retrieved 2023-10-17.\\n\\n^ \"Announcing the General Availability of LangSmith and Our Series A Led By Sequoia Capital\". LangChain Blog. 2024-02-15. Retrieved 2025-08-03.\\n\\n^ \"LangGraph Platform is now Generally Available: Deploy & manage long-running, stateful Agents\". LangChain Blog. 2025-05-14. Retrieved 2025-08-03.\\n\\n^ \"Azure Cognitive Search and LangChain: A Seamless Integration for Enhanced Vector Search Capabilities\". TECHCOMMUNITY.MICROSOFT.COM. Retrieved 2024-08-31.\\n\\n^ \"Best Alternative AI Content Strategies and LLM Frameworks\". Medium. 2024-08-31. Retrieved 2024-08-31.\\n\\n^ \"Milvus — LangChain\". python.langchain.com. Retrieved 2023-10-29.\\n\\n^ \"Weaviate\". python.langchain.com. Retrieved 2024-01-17.\\n\\n^ Hug, Daniel Patrick (2023-03-08). \"Hierarchical topic tree of LangChain\\'s integrations\" (PDF). GitHub. Archived from the original on 2023-04-29. Retrieved 2023-04-18.\\n\\n^ \"Document Loaders — LangChain 0.0.142\". python.langchain.com. Archived from the original on 2023-04-18. Retrieved 2023-04-18.\\n\\n\\nExternal links[edit]\\n\\n\\nLangChain  at Wikipedia\\'s sister projects\\n\\nMedia from CommonsData from Wikidata'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is langchain?\"\n",
    "\n",
    "retrieved_docs = retriever1.invoke(query)\n",
    "\n",
    "context1 = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "context1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87f31b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'History[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\nIn the third quarter of 2023, the LangChain Expression Language (LCEL) was introduced, which provides a declarative way to define chains of actions.[5][6]\\nIn October 2023 LangChain introduced LangServe, a deployment tool to host LCEL code as a production-ready API.[7]\\n\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\nIn the third quarter of 2023, the LangChain Expression Language (LCEL) was introduced, which provides a declarative way to define chains of actions.[5][6]\\nIn October 2023 LangChain introduced LangServe, a deployment tool to host LCEL code as a production-ready API.[7]\\n\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\nIn the third quarter of 2023, the LangChain Expression Language (LCEL) was introduced, which provides a declarative way to define chains of actions.[5][6]\\nIn October 2023 LangChain introduced LangServe, a deployment tool to host LCEL code as a production-ready API.[7]\\n\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\nIn the third quarter of 2023, the LangChain Expression Language (LCEL) was introduced, which provides a declarative way to define chains of actions.[5][6]\\nIn October 2023 LangChain introduced LangServe, a deployment tool to host LCEL code as a production-ready API.[7]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is langchain?\"\n",
    "\n",
    "retrieved_docs = retriever2.invoke(query)\n",
    "\n",
    "context2 = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "context2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Azure OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2803de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    prompt=\"\",\n",
    "    azure_deployment=\"gpt-4.1\",  # your Azure deployment name\n",
    "    api_version=\"\",\n",
    "    temperature=0,\n",
    "    azure_endpoint=\"\",\n",
    "    api_key=\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a38c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "rag_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are an assistant answering questions strictly using the provided context.\n",
    "\n",
    "If the answer is not present in the context, say:\n",
    "\"I don't know based on the provided context.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4191de3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc817350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain1 = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever1,\n",
    "    chain_type=\"stuff\",# this is for multidocuments\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": rag_prompt\n",
    "    },\n",
    "    return_source_documents=True\n",
    ")\n",
    "qa_chain2 = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever2,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": rag_prompt\n",
    "    },\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b9fd4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " I don't know based on the provided context.\n",
      "Answer:\n",
      " LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who won the IPL 2025?\"\n",
    "result = qa_chain1(query)\n",
    "\n",
    "print(\"Answer:\\n\", result[\"result\"])\n",
    "\n",
    "\n",
    "query = \"What is Langchain?\"\n",
    "result = qa_chain1(query)\n",
    "\n",
    "print(\"Answer:\\n\", result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db07bbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " I don't know based on the provided context.\n",
      "Answer:\n",
      " LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who won the IPL 2025?\"\n",
    "result = qa_chain1(query)\n",
    "\n",
    "print(\"Answer:\\n\", result[\"result\"])\n",
    "\n",
    "\n",
    "query = \"What is Langchain?\"\n",
    "result = qa_chain1(query)\n",
    "\n",
    "print(\"Answer:\\n\", result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0e57ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9c332d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Ollama LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e226247c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gc/_6pc4cjj1_39_1622f88r3d00000gt/T/ipykernel_96344/2388233276.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3\",\n",
    "    temperature=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0583ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain1 = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever1,\n",
    "    chain_type=\"stuff\",# this is for multidocuments\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": rag_prompt\n",
    "    },\n",
    "    return_source_documents=True\n",
    ")\n",
    "qa_chain2 = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever2,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": rag_prompt\n",
    "    },\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce4501a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " I don't know based on the provided context. The context only talks about Langchain-ai, OpenAI, and related topics, but does not mention the Indian Premier League (IPL) or any information about its winners in 2025.\n",
      "Answer:\n",
      " According to the provided context, LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who won the IPL 2025?\"\n",
    "result = qa_chain1(query)\n",
    "\n",
    "print(\"Answer:\\n\", result[\"result\"])\n",
    "\n",
    "\n",
    "query = \"What is Langchain?\"\n",
    "result = qa_chain1(query)\n",
    "\n",
    "print(\"Answer:\\n\", result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04b18a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " I don't know based on the provided context. The context only talks about Langchain-ai, OpenAI, and related topics, but does not mention the Indian Premier League (IPL) or any information about its winners in 2025.\n",
      "Answer:\n",
      " According to the provided context, LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who won the IPL 2025?\"\n",
    "result = qa_chain1(query)\n",
    "\n",
    "print(\"Answer:\\n\", result[\"result\"])\n",
    "\n",
    "\n",
    "query = \"What is Langchain?\" \n",
    "result = qa_chain1(query)\n",
    "\n",
    "print(\"Answer:\\n\", result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a1e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
